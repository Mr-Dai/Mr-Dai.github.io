---
layout: posts
title: Spark Catalyst 进阶：CacheManager
author: Robert Peng
category: Spark
---
<script type="text/javascript" src="/js/syntaxhighlighters/shBrushScala.js"></script>
<h2 class="jump">前情提要</h2>
<p>
	在<a href="/2015/08/17/SparkSQL-Catalyst-Source-1.html">上一个系列</a>以及<a href="/2015/08/19/SparkSQL-Catalyst-Adv-1.html">上一篇文章</a>中，我们详细讲解了SparkSQL如何一步一步地将用户输入的SQL语句变为LogicalPlan再变为PhysicalPlan。
	至此，这个流程本身的内容已经全部讲完了，因此接下来的文章我们将脱离这个主要流程，去讲解SparkSQL的其他常用功能。
</p>
<p>
	在今天的这篇文章中，我们先从SparkSQL的DataFrame Cache机制开始讲起。
</p>

<h2 class="jump">CacheManager</h2>
<p>
	在我之前推荐的<a href="/file/SparkSQL.pdf">那篇论文</a>中实际上有稍微提到SparkSQL的缓存机制。我们都知道RDD可以以Partition为单位进行缓存，
	对于一些经常需要大量计算但计算结果基本不变且经常需要查询的数据，我们就会考虑使用RDD的缓存机制。SparkSQL中也是同理。平日的数据库访问中我们经常需要访问一些由两张表Join得到的数据。
	这些数据查询频次高、计算复杂度高，但计算的结果在短时间内是基本不变的。为了做到实时性，对于这样的DataFrame我们就可以考虑使用DataFrame的Cache机制。
</p>
<p>
	通常，我们通过调用<code>DataFrame</code>的<code>cache</code>方法或<code>persist</code>方法来对其进行缓存。实际上这两个操作是完全相同的。
	我们来看一下它们的源代码：
</p>
<pre class="brush: scala">
class DataFrame private[sql](
    @transient val sqlContext: SQLContext,
    @DeveloperApi @transient val queryExecution: SQLContext#QueryExecution)
  extends RDDApi[Row] with Serializable {
  
  // ...
  
  override def cache(): this.type = persist() // 由此可见，这两个接口是完全相同的
  
  // 调用了SQLContext的cacheManager来完成Cache动作
  override def persist(): this.type = {
    sqlContext.cacheManager.cacheQuery(this)
    this
  }

  // 除此之外，persist接口还允许用户传入不同的存储级别。可用于DataFrame的存储级别与RDD的完全相同
  override def persist(newLevel: StorageLevel): this.type = {
    sqlContext.cacheManager.cacheQuery(this, None, newLevel)
    this
  }  
 
  // ...
}
</pre>
<p>那我们再去看看<code>SQLContext</code>的这个<code>cacheManager</code>是什么：</p>
<pre class="brush: scala">
protected[sql] val cacheManager = new CacheManager(this) // 很好，简单粗暴
</pre>
<p>
	由此一来我们就知道这个变量实际上就是个<code>CacheManager</code>实例，<code>DataFrame</code>通过以自己为参数调用它的<code>cacheQuery</code>方法来完成缓存动作。
	那么我们就来看一下<code>CacheManager</code>：
</p>
<pre class="brush: scala">
/** Holds a cached logical plan and its data */
private[sql] case class CachedData(plan: LogicalPlan, cachedRepresentation: InMemoryRelation)
// 从命名上看，这应该是个用来表示单张缓存表的bean类，其中包含一个表示其所代表的查询的LogicalPlan。
// InMemoryRelation类尚不明朗，但从名字上看，这应该是个LogicalPlan + LeafNode的实现类

private[sql] class CacheManager(sqlContext: SQLContext) extends Logging {

  @transient
  private val cachedData = new scala.collection.mutable.ArrayBuffer[CachedData]
  // 通过一个ArrayBuffer管理注册到该manager中的DataFrame

  @transient
  private val cacheLock = new ReentrantReadWriteLock
  // 使用一个可重入读写锁来对Cache内容进行加锁

  /** Returns true if the table is currently cached in-memory. */
  def isCached(tableName: String): Boolean = lookupCachedData(sqlContext.table(tableName)).nonEmpty
  // 检查某张表是否被cache到了内存中。这里调用了一个新方法lookupCachedData

  /** Caches the specified table in-memory. */
  def cacheTable(tableName: String): Unit = cacheQuery(sqlContext.table(tableName), Some(tableName))
  // 将某张表cache到内存中。这里再次调用了cacheQuery方法

  /** Removes the specified table from the in-memory cache. */
  def uncacheTable(tableName: String): Unit = uncacheQuery(sqlContext.table(tableName))
  // 将某张表从内存中移除

  /** 为f过程赋一个读锁 */
  private def readLock[A](f: => A): A = {
    val lock = cacheLock.readLock()
    lock.lock()
    try f finally {
      lock.unlock()
    }
  }

  /** 为f过程赋一个写锁 */
  private def writeLock[A](f: => A): A = {
    val lock = cacheLock.writeLock()
    lock.lock()
    try f finally {
      lock.unlock()
    }
  }

  /** 清除所有缓存表。涉及缓存内容修改，因此这里申请了一个写锁 */
  private[sql] def clearCache(): Unit = writeLock {
    // 这里调用了InMemoryRelation的cachedColumnBuffers变量的unpersist方法来从内存中物理地移除缓存
    cachedData.foreach(_.cachedRepresentation.cachedColumnBuffers.unpersist())
	// 之所以说是物理的，毫无疑问CachedData本身只是一些元数据，单纯的cacheData.clear是不够的
    cachedData.clear()
	// 当然最后还是得clear一下才行
  }

  /** 检查是否有缓存内容。涉及读取缓存内容，申请了一个读锁 */
  private[sql] def isEmpty: Boolean = readLock {
    cachedData.isEmpty
  }

  /**
   * 对传入的Logical Plan（实际指DataFrame）进行缓存。这里使用的默认存储级别为MEMORY_AND_DISK，
   * 因为计算表的列存储表示的过程代价过高。
   *
   * 涉及缓存写操作，申请了一个写锁
   */
  private[sql] def cacheQuery(
      query: DataFrame,
      tableName: Option[String] = None,
      storageLevel: StorageLevel = MEMORY_AND_DISK): Unit = writeLock {
	// 获取到DataFrame的Analyzed Logical Plan
    val planToCache = query.queryExecution.analyzed
	// 先看看这个Plan是否已经cache了
    if (lookupCachedData(planToCache).nonEmpty) {
      logWarning("Asked to cache already cached data.")
    } else {
	  // 没有的话才cache
      cachedData +=
        CachedData(
          planToCache,  // CachedData中保存的是一个Analyzed Logical Plan
          InMemoryRelation(
            sqlContext.conf.useCompression,
            sqlContext.conf.columnBatchSize,
            storageLevel,
            query.queryExecution.executedPlan, // 但InMemoryRelation中保存的是一个Prepared Physical Plan
            tableName))
    }
  }

  /** 根据给定的DataFrame从缓存中移除数据。申请了一个写锁 */
  private[sql] def uncacheQuery(query: DataFrame, blocking: Boolean = true): Unit = writeLock {
    val planToCache = query.queryExecution.analyzed
	// 通过调用LogicalPlan的sameResult方法来在cachedData中找到对应位置
    val dataIndex = cachedData.indexWhere(cd => planToCache.sameResult(cd.plan))
    require(dataIndex >= 0, s"Table $query is not cached.")
	// 物理移除
    cachedData(dataIndex).cachedRepresentation.uncache(blocking)
	// 逻辑移除
    cachedData.remove(dataIndex)
  }

  /**
   * 尝试根据给定的DataFrame从缓存中移除数据。申请了一个写锁。
   *
   * 该方法与上一个方法的不同在于，上一个方法如果没有在cachedData中找到对应的元素会直接抛出一个错误，
   * 但这个方法不会。
   */
  private[sql] def tryUncacheQuery(
      query: DataFrame,
      blocking: Boolean = true): Boolean = writeLock {
    val planToCache = query.queryExecution.analyzed
    val dataIndex = cachedData.indexWhere(cd => planToCache.sameResult(cd.plan))
    val found = dataIndex >= 0
    if (found) {
      cachedData(dataIndex).cachedRepresentation.cachedColumnBuffers.unpersist(blocking)
      cachedData.remove(dataIndex)
    }
    found
  }

  /** 使用传入DataFrame的Analyzed Logical Plan来查找cachedData */
  private[sql] def lookupCachedData(query: DataFrame): Option[CachedData] = readLock {
    lookupCachedData(query.queryExecution.analyzed)
  }

  /** 使用传入的Analyzed Logical Plan来查找cachedData */
  private[sql] def lookupCachedData(plan: LogicalPlan): Option[CachedData] = readLock {
    // 这里同样利用了LogicalPlan的sameResult方法
    cachedData.find(cd => plan.sameResult(cd.plan))
  }

  /**
   * 尝试将传入的LogicalPlan中吻合的子树替换为缓存内容
   * 在SQLContext#QueryExecution中，得出Analyzed Logical Plan以后，
   * 会在转换为PhysicalPlan之前调用该方法。
   */
  private[sql] def useCachedData(plan: LogicalPlan): LogicalPlan = {
    plan transformDown {
      case currentFragment =>
        lookupCachedData(currentFragment)
          .map(_.cachedRepresentation.withOutput(currentFragment.output))
          .getOrElse(currentFragment)
	  // 在cachedData中找到相同的Plan，便将其替换为了一个InMemoryRelation
	  // 这里还调用了InMemoryRelation的withOutput方法，传入了原本的LogicalPlan的output	  
    }
  }

  /**
   * 使包含传入LogicalPlan的缓存数据失效
   */
  private[sql] def invalidateCache(plan: LogicalPlan): Unit = writeLock {
    cachedData.foreach {
	  // 只要某个cachedData包含了该子树，便会调用它的InMemoryRelation的recache方法
      case data if data.plan.collect { case p if p.sameResult(plan) => p }.nonEmpty =>
        data.cachedRepresentation.recache()
      case _ =>
    }
  }
}
</pre>
<p>
	经过一番阅读，我们了解到，SparkSQL通过对Analyzed Logical Plan调用useCachedData方法，便会将执行计划树中与某个已缓存数据相吻合的子树替换为一个<code>InMemoryRelation</code>。
	我们之前就接触过Relation，它主要指的是SQL中<code>FROM</code>关键字指明的表名，所以这里的<code>InMemoryRelation</code>也可以理解为直接从内存中SELECT FROM。
    在注册缓存时，<code>CacheManager</code>利用了一些设置参数、表名、DataFrame的Physical Plan来实例化一个<code>InMemoryRelation</code>。
</p>
<h2 class="jump">InMemoryRelation</h2>
<p>那我们就来看一下这个<code>InMemoryRelation</code>：</p>
<pre class="brush: scala">
private[sql] object InMemoryRelation {
  // CacheManager就是应用这个方法来创建InMemoryRelation实例的
  def apply(
      useCompression: Boolean,
      batchSize: Int,
      storageLevel: StorageLevel,
      child: SparkPlan,
      tableName: Option[String]): InMemoryRelation =
    new InMemoryRelation(child.output, useCompression, batchSize, storageLevel, child, tableName)()
  // 并未对参数进行任何特别的处理，只是把一个child.output提取出来又传了进去	
}

// 暂不清楚这是什么，但它包含了一个Array[Array[Byte]]，这个很有可能就是缓存数据保存在内存中的形式
private[sql] case class CachedBatch(buffers: Array[Array[Byte]], stats: Row)

private[sql] case class InMemoryRelation(
    output: Seq[Attribute],
    useCompression: Boolean,
    batchSize: Int,
    storageLevel: StorageLevel,
    child: SparkPlan,
    tableName: Option[String])(
	// 注意这里有个CachedBatch的RDD，这个应该就是指这张表的缓存数据
    private var _cachedColumnBuffers: RDD[CachedBatch] = null,
    private var _statistics: Statistics = null,
    private var _batchStats: Accumulable[ArrayBuffer[Row], Row] = null)
  extends LogicalPlan with MultiInstanceRelation {
  // 果然InMemoryRelation继承自LogicalPlan，但这个MultiInstanceRelation倒是个新名词

  private val batchStats: Accumulable[ArrayBuffer[Row], Row] =
    if (_batchStats == null) {
      child.sqlContext.sparkContext.accumulableCollection(ArrayBuffer.empty[Row])
    } else {
      _batchStats
    }

  // 暂不清楚是什么	
  val partitionStatistics = new PartitionStatistics(output)

  // 计算缓存数据的大小
  private def computeSizeInBytes = {
    val sizeOfRow: Expression =
	  // 需要先了解一下BindReferences是什么
      BindReferences.bindReference(
        output.map(a => partitionStatistics.forAttribute(a).sizeInBytes).reduce(Add),
        partitionStatistics.schema)

    batchStats.value.map(row => sizeOfRow.eval(row).asInstanceOf[Long]).sum
  }

  // 传播用的statistics
  private def statisticsToBePropagated = if (_statistics == null) {
    val updatedStats = statistics
    if (_statistics == null) null else updatedStats
  } else {
    _statistics
  }

  // 重载了Statistics逻辑（原本的默认实现是左子 * 右子）
  override def statistics: Statistics = {
    if (_statistics == null) {
      if (batchStats.value.isEmpty) {
        // Underlying columnar RDD hasn't been materialized, no useful statistics information
        // available, return the default statistics.
        Statistics(sizeInBytes = child.sqlContext.conf.defaultSizeInBytes)
      } else {
        // Underlying columnar RDD has been materialized, required information has also been
        // collected via the `batchStats` accumulator, compute the final statistics,
        // and update `_statistics`.
        _statistics = Statistics(sizeInBytes = computeSizeInBytes)
        _statistics
      }
    } else {
      // Pre-computed statistics
      _statistics
    }
  }

  // If the cached column buffers were not passed in, we calculate them in the constructor.
  // As in Spark, the actual work of caching is lazy.
  if (_cachedColumnBuffers == null) {
    // 构建缓存
    buildBuffers()
  }

  // 重新缓存
  def recache(): Unit = {
    // 清空了缓存
    _cachedColumnBuffers.unpersist()
    _cachedColumnBuffers = null
	// 建立缓存
    buildBuffers()
  }

  // 建立缓存
  private def buildBuffers(): Unit = {
    // 注意：child是传进来的那个DataFrame的Physical Plan
    val output = child.output
	// 执行
    val cached = child.execute().mapPartitions { rowIterator =>
	  // 为每一个Partition都生成了一个Iterator，想必之后会利用这些Iterator来访问缓存数据
      new Iterator[CachedBatch] {
	    // 这里我们就了解到，CachedBatch表示的是一个Partition的缓存
        def next(): CachedBatch = {
		  // 这里对每个Attribute都生成了一个ColumnBuilder
		  // 考虑到SparkSQL的缓存是以列存储的形式组织的，那么下一步大概就是要利用这些ColumnBuilder构建缓存了
          val columnBuilders = output.map { attribute =>
            val columnType = ColumnType(attribute.dataType)
            val initialBufferSize = columnType.defaultSize * batchSize
			// 这里看到ColumnBuilder本身包含的信息只是一些元数据
            ColumnBuilder(attribute.dataType, initialBufferSize, attribute.name, useCompression)
          }.toArray

          var rowCount = 0
		  // 遍历整个Partition
          while (rowIterator.hasNext && rowCount &lt; batchSize) {
            val row = rowIterator.next()

			// ...

			// 将该行的数据放入到各自的ColumnBuilder中   
            var i = 0
            while (i &lt; row.length) {
              columnBuilders(i).appendFrom(row, i)
              i += 1
            }
            rowCount += 1
          }

		  // 不知道在干什么
          val stats = Row.merge(columnBuilders.map(_.columnStats.collectedStatistics) : _*)

          batchStats += stats
		  // 返回了该Partition的缓存数据
          CachedBatch(columnBuilders.map(_.build().array()), stats)
        }

        def hasNext: Boolean = rowIterator.hasNext
      }
    }.persist(storageLevel)
	// 将整个RDD缓存。注意：这个动作是lazy的

    cached.setName(tableName.map(n => s"In-memory table $n").getOrElse(child.toString))
    _cachedColumnBuffers = cached
  }

  // 利用传入的output新建一个实例
  def withOutput(newOutput: Seq[Attribute]): InMemoryRelation = {
    InMemoryRelation(
      newOutput, useCompression, batchSize, storageLevel, child, tableName)(
      _cachedColumnBuffers, statisticsToBePropagated, batchStats)
  }

  // 无children，说到底它还是一个叶子节点
  override def children: Seq[LogicalPlan] = Seq.empty

  // 拷贝构造函数
  override def newInstance(): this.type = {
    new InMemoryRelation(
      output.map(_.newInstance()),
      useCompression,
      batchSize,
      storageLevel,
      child,
      tableName)(
      _cachedColumnBuffers,
      statisticsToBePropagated,
      batchStats).asInstanceOf[this.type]
  }

  def cachedColumnBuffers: RDD[CachedBatch] = _cachedColumnBuffers

  override protected def otherCopyArgs: Seq[AnyRef] =
    Seq(_cachedColumnBuffers, statisticsToBePropagated, batchStats)

  // 移除缓存	
  private[sql] def uncache(blocking: Boolean): Unit = {
    // 不清楚在干啥
    Accumulators.remove(batchStats.id)
	// 移除了缓存数据
    cachedColumnBuffers.unpersist(blocking)
    _cachedColumnBuffers = null
  }
}
</pre>
<p>
	目前来讲，我们已经能看懂大部分的代码。其中出现了一个<code>ColumnBuilder</code>，正是用来构建列缓存的类。那我们去看看这个<code>ColumnBuilder</code>：
</p>
<pre class="brush: scala">
// 完蛋了，这居然只是个接口
private[sql] trait ColumnBuilder {
  // 初始化
  def initialize(initialSize: Int, columnName: String = "", useCompression: Boolean = false)

  // 将该行指定的元素放入到ColumnBuilder 
  def appendFrom(row: Row, ordinal: Int)

  // Statistics Information
  def columnStats: ColumnStats

  // 返回最终的列缓存
  def build(): ByteBuffer
}
</pre>
<p>我们先不着急看它的实现类，我们先去看看它的实例化方法：</p>
<pre class="brush: scala">
private[sql] object ColumnBuilder {
  // 默认的初始缓存大小，1MB
  val DEFAULT_INITIAL_BUFFER_SIZE = 1024 * 1024

  // 保证空余空间。这里我们就可以看出来，ByteBuffer就是最底层的缓存数据容器了
  private[columnar] def ensureFreeSpace(orig: ByteBuffer, size: Int) = {
    // 有足够的空闲空间，则不需要做任何操作
    if (orig.remaining >= size) {
      orig
    } else {
	  // 空闲空间不足，尝试扩充ByteBuffer
      // grow in steps of initial size
      val capacity = orig.capacity()
      val newSize = capacity + size.max(capacity / 8 + 1)
      val pos = orig.position()

	  // 新建一个更大的ByteBuffer并放入原ByteBuffer的数据
      ByteBuffer
        .allocate(newSize)
        .order(ByteOrder.nativeOrder())
        .put(orig.array(), 0, pos)
    }
  }

  // InMemoryRelation就是通过这个方法实例化ColumnBuilder的
  def apply(
      dataType: DataType,
      initialSize: Int = 0,
      columnName: String = "",
      useCompression: Boolean = false): ColumnBuilder = {
	// 如此看来，ColumnBuilder是根据传入的数据类型来实例化不同的子类
    val builder: ColumnBuilder = dataType match {
      case IntegerType => new IntColumnBuilder
      case LongType => new LongColumnBuilder
      case FloatType => new FloatColumnBuilder
      case DoubleType => new DoubleColumnBuilder
      case BooleanType => new BooleanColumnBuilder
      case ByteType => new ByteColumnBuilder
      case ShortType => new ShortColumnBuilder
      case StringType => new StringColumnBuilder
      case BinaryType => new BinaryColumnBuilder
      case DateType => new DateColumnBuilder
      case TimestampType => new TimestampColumnBuilder
      case DecimalType.Fixed(precision, scale) if precision &lt; 19 =>
        new FixedDecimalColumnBuilder(precision, scale)
      case _ => new GenericColumnBuilder
    }
    // 初始化后便实例化完毕
    builder.initialize(initialSize, columnName, useCompression)
    builder
  }
}
</pre>
<p>
	由此看来，<code>ColumnBuilder</code>的工作是构建一个列缓存，但列缓存本身由一个<code>ByteBuffer</code>表示，所以<code>build</code>方法返回的是一个<code>ByteBuffer</code>。
	<code>ByteBuffer</code>实际上是一个抽象类，它来自<code>java.nio</code>包。通过调用<code>ByteBuffer</code>的静态方法来获取其子类实例可以让外部调用者不去在意其底部的内存分配方式。
</p>
<p>实际上，<code>ColumnBuilder</code>的子类们有着极为复杂的继承关系。画成类图大致如下：</p>
<p class="center"><img style="width: 100%" alt="" src="/img/Catalyst-Adv@2.jpg"></p>
<p style="padding: 0" class="center">（右键在新标签页中查看大图）</p>
<p>由此看来，我们最好不要再往下深究。</p>
<p>除了<code>ColumnBuilder</code>，我们还需要关注出现在<code>InMemoryRelation</code>中的<code>PartitionStatistics</code>。我们来看看它的代码：</p>
<pre class="brush: scala">
// 实例化时，InMemoryRelation会把Physical Plan的output作为参数传入
private[sql] class PartitionStatistics(tableSchema: Seq[Attribute]) extends Serializable {
  // 这里同时设定了它的两个变量
  val (forAttribute, schema) = {
    // 这里形成了一个从Attribute到它的ColumnStatisticsSchema实例的映射
    val allStats = tableSchema.map(a => a -> new ColumnStatisticsSchema(a))
    (AttributeMap(allStats), allStats.map(_._2.schema).foldLeft(Seq.empty[Attribute])(_ ++ _))
	// 这里前者是一个从Attribute.exprId到ColumnStatisticsSchema的映射
    // 后者则是ColumnStatisticsSchema们的schema变量的首尾相连
  }
}

// 实际上ColumnStatisticsSchema的定义就在这个类的上面
private[sql] class ColumnStatisticsSchema(a: Attribute) extends Serializable {
  // AttributeReference是Attribute的一个实现类，是一个case class
  val upperBound = AttributeReference(a.name + ".upperBound", a.dataType, nullable = true)()
  val lowerBound = AttributeReference(a.name + ".lowerBound", a.dataType, nullable = true)()
  val nullCount = AttributeReference(a.name + ".nullCount", IntegerType, nullable = false)()
  val count = AttributeReference(a.name + ".count", IntegerType, nullable = false)()
  val sizeInBytes = AttributeReference(a.name + ".sizeInBytes", LongType, nullable = false)()

  // 这里看到对于每个传入的Attribute，生成的schema实际上就是这样5个元素组成的Seq
  // 从上面可以看到，这其中的信息包括了Attribute的名字、类型、上下界、是否可为null、大小，以及一个不知道指代什么的count
  val schema = Seq(lowerBound, upperBound, nullCount, count, sizeInBytes)
  // 该类的名字叫ColumnStatisticsSchema，从它把一个Attribute拆成5个Attribute的行为来看，它确实是一个Schema，
  // 而这五个元素应该就是这个Column的Statistics了
}
</pre>
<p>
	这里只能看出，<code>PartitionStatistics</code>倒是做了个很奇怪的工作，而且<code>InMemoryRelation</code>再没用到过它。
	也许后面会有什么地方用到它。
</p>
<p>
	至此，我们就知道，在实例化<code>InMemoryRelation</code>的时候就已经完成了<code>RDD.persist</code>的动作，但我们也要知道RDD的缓存本身是lazy的，
	即使调用了这个<code>persist</code>方法，真正的缓存动作是还没有执行的。
</p>
<p>接下来我们开始看看SparkSQL会如何获取这些缓存数据。</p>
<h2 class="jump">InMemoryColumnarTableScan</h2>
<p>
	之前我们学习到，Optimized Logical Plan由<code>SparkPlanner</code>转变为Physical Plan，而<code>SparkPlanner</code>所应用的转换策略都位于<code>SparkStrategies</code>中。
	那么我们就去看一下：
</p>
<pre class="brush: scala">
// 经搜索发现，InMemoryRelation仅在此处出现过
object InMemoryScans extends Strategy {
  def apply(plan: LogicalPlan): Seq[SparkPlan] = plan match {
    // 这里对传入的plan调用了PhysicalOperation的unapply方法
    case PhysicalOperation(projectList, filters, mem: InMemoryRelation) =>
      pruneFilterProject(
        projectList,
        filters,
        identity[Seq[Expression]], // All filters still need to be evaluated.
        InMemoryColumnarTableScan(_, filters, mem)) :: Nil
    case _ => Nil
  }
}
</pre>
<p>那我们先去看看这个<code>PhysicalOperation</code>：</p>
<pre class="brush: scala">
object PhysicalOperation extends PredicateHelper {
  type ReturnType = (Seq[NamedExpression], Seq[Expression], LogicalPlan)

  def unapply(plan: LogicalPlan): Option[ReturnType] = {
    val (fields, filters, child, _) = collectProjectsAndFilters(plan)
	// 从之前InMemoryScans的代码可知，InMemoryRelation指的是这里的child，也就是collectProjectsAndFilters的第三个结果
    Some((fields.getOrElse(child.output), filters, child))
  }

  // 我们只考虑传入的LogicalPlan是个InMemoryRelation的情况
  def collectProjectsAndFilters(plan: LogicalPlan):
      (Option[Seq[NamedExpression]], Seq[Expression], LogicalPlan, Map[Attribute, Expression]) =
    plan match {
	  // Project是个case class，InMemoryRelation不会进入这个分支
      case Project(fields, child) =>
        val (_, filters, other, aliases) = collectProjectsAndFilters(child)
        val substitutedFields = fields.map(substitute(aliases)).asInstanceOf[Seq[NamedExpression]]
        (Some(substitutedFields), filters, other, collectAliases(substitutedFields))

	  // Filter同样是个case class
      case Filter(condition, child) =>
        val (fields, filters, other, aliases) = collectProjectsAndFilters(child)
        val substitutedCondition = substitute(aliases)(condition)
        (fields, filters ++ splitConjunctivePredicates(substitutedCondition), other, aliases)

	  // 毫无疑问，InMemoryRelation会进入这个分支，作为第三个结果被原封不动地返回，同时前两个结果都是空	
      case other =>
        (None, Nil, other, Map.empty)
    }
	
  // ...

}  
</pre>
<p>那么回到刚才的Strategy：</p>
<pre class="brush: scala">
object InMemoryScans extends Strategy {
  def apply(plan: LogicalPlan): Seq[SparkPlan] = plan match {
    case PhysicalOperation(projectList, filters, mem: InMemoryRelation) =>
	  // 也就是说到了这里，projectList和filters都是空
      pruneFilterProject(
        projectList,
        filters,
        identity[Seq[Expression]], // All filters still need to be evaluated.
        InMemoryColumnarTableScan(_, filters, mem)) :: Nil
		// 这里构建了一个InMemoryColumnarTableScan实例
    case _ => Nil
  }
}
</pre>
<p>这下好像找到点眉头了。那么我们来看一下这个<code>InMemoryColumnarTableScan</code>：</p>
<pre class="brush: scala">
private[sql] case class InMemoryColumnarTableScan(
    attributes: Seq[Attribute],
    predicates: Seq[Expression],
    relation: InMemoryRelation)
  extends LeafNode {
  // 它通过LeafNode继承自SparkPlan，由此可以确定这个类正是InMemoryRelation对应的Physical Plan

  override def output: Seq[Attribute] = attributes

  // 这里再次用到了InMemoRelation那个很奇怪的变量
  // 这个变量的forAttribute是一个基于Attribute.exprId的从Attribute到ColumnStatisticsSchema的映射
  private def statsFor(a: Attribute) = relation.partitionStatistics.forAttribute(a)

  // ...

  // SparkPlan的入口方法
  protected override def doExecute(): RDD[Row] = {
    // ...

	// 这个cachedColumnBuffers就是之前InMemoryRelation构建好的RDD[CachedBatch]
    relation.cachedColumnBuffers.mapPartitions { cachedBatchIterator =>
      // ...

      // 找出需要的列的索引以及数据类型
      val (requestedColumnIndices, requestedColumnDataTypes) = if (attributes.isEmpty) {
	    // 未传入任何属性，返回默认体积最小的列
        val (narrowestOrdinal, narrowestDataType) =
          relation.output.zipWithIndex.map { case (a, ordinal) =>
		  // Index  ->  DataType
            ordinal -> a.dataType
          } minBy { case (_, dataType) =>
            ColumnType(dataType).defaultSize
          }
        Seq(narrowestOrdinal) -> Seq(narrowestDataType)
      } else {
	    // 否则，根据传入的exprId找到对应的Index
        attributes.map { a =>
          relation.output.indexWhere(_.exprId == a.exprId) -> a.dataType
        }.unzip
      }

      val nextRow = new SpecificMutableRow(requestedColumnDataTypes)

	  // 将CachedBatch转换为Row
      def cachedBatchesToRows(cacheBatches: Iterator[CachedBatch]): Iterator[Row] = {
        val rows = cacheBatches.flatMap { cachedBatch =>
          // 创建ColumnAccessor读取缓存数据
          val columnAccessors = requestedColumnIndices.map { batchColumnIndex =>
            ColumnAccessor(
              relation.output(batchColumnIndex).dataType,
              ByteBuffer.wrap(cachedBatch.buffers(batchColumnIndex)))
          }

          // 通过ColumnAccessor将数据解压至Row
          new Iterator[Row] {
            private[this] val rowLen = nextRow.length
            override def next(): Row = {
              var i = 0
              while (i &lt; rowLen) {
                columnAccessors(i).extractTo(nextRow, i)
                i += 1
              }
              if (attributes.isEmpty) Row.empty else nextRow
            }

            override def hasNext: Boolean = columnAccessors(0).hasNext
          }
        }

        if (rows.hasNext && enableAccumulators) {
          readPartitions += 1
        }

        rows
      }

      // 需要扫描的CachedBatch
      val cachedBatchesToScan =
	    // 该参数默认为false
        if (inMemoryPartitionPruningEnabled) {
          cachedBatchIterator.filter { cachedBatch =>
            if (!partitionFilter(cachedBatch.stats)) {
              def statsString: String = relation.partitionStatistics.schema
                .zip(cachedBatch.stats.toSeq)
                .map { case (a, s) => s"${a.name}: $s" }
                .mkString(", ")
              logInfo(s"Skipping partition based on stats $statsString")
              false
            } else {
              if (enableAccumulators) {
                readBatches += 1
              }
              true
            }
          }
        } else {
		  // 默认扫描所有CachedBatch
          cachedBatchIterator
        }

      cachedBatchesToRows(cachedBatchesToScan)
    }
  }
}
</pre>
<p>至此其实我们就全部理解了。</p>
