<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    
    <link href="/css/bootstrap.min.css" rel="stylesheet">
    <link href="/css/default.css" rel="stylesheet">
	<link href="/css/post.css" rel="stylesheet">
    <script type="text/javascript" src="/js/jquery-2.1.1.min.js"></script>
    
    <script type="text/javascript" src="/js/syntaxhighlighters/shCore.js"></script>
    <link href="/css/syntaxhighlighters/shCore.css" rel="stylesheet" type="text/css" />
    <link href="/css/syntaxhighlighters/shThemeDefault.css" rel="stylesheet" type="text/css" />
	
	<link rel="shortcut icon" href="/img/favicon.ico" >
    
    <title>SparkSQL Hive ThriftServer 源码解析（二）：SparkSQLCLIService - Robert Peng</title>
</head>
<body>
	<script src="/js/bootstrap.min.js"></script>
	<script src="/js/mrdai.js"></script>
    <div id="main_wrapper">
    <div id="banner_wrapper">
    <h1 style="padding-bottom:0">Robert P.'s Blog</h1>
	<p style="margin-top:8px; color: #999999; font-size: 22px">Blog is how I learn.</p>
    </div>
    <div id="content_wrapper">
        <div id="right_wrapper" style="margin-left: 10px; width: 30%; font-size:15px; line-height:25px;">
            <ul id="JumpList">
                <li><h4>跳转目录</h4></li>
            </ul>
        </div>
		<div id="left_wrapper">
			<p style="color: rgb(50, 93, 114); font-size:30px; font-weight:300; margin-top: 0; padding-top: 30px;">SparkSQL Hive ThriftServer 源码解析（二）：SparkSQLCLIService</p>
			<p style="font-size:15px; margin-top: 0; color: #BBB"><em>By Robert Peng</em>, 30 Jul 2015</p>
			<!-- content starts here -->
			<script type="text/javascript" src="/js/syntaxhighlighters/shBrushBash.js"></script>
<script type="text/javascript" src="/js/syntaxhighlighters/shBrushJava.js"></script>
<script type="text/javascript" src="/js/syntaxhighlighters/shBrushScala.js"></script>

<h2 class="jump">前情提要</h2>
<p>此文接<a href="/applications/2015/07/27/SparkSQL-HiveThriftServer-Source-1.html">上文</a>，继续讲解SparkSQL Hive ThriftServer源码。</p>
<p>
	上文提到，主类HiveThriftServer2在启动后便会启动ThriftCLIService和SparkSQLCLIService，
	其中ThriftCLIService负责维护与客户端的连接并将客户端的请求转发至SparkSQLCLIService，
	由SparkSQLCLIService执行运算并把结果返回给ThriftCLIService，ThriftCLIService再把结果以ResultSet的形式返回给客户端。
	两者之间的关系如下图所示：
</p>
<p class="center"><img style="width: 100%" alt="" src="/img/SparkSQL@2.jpg"></p>
<p>
	但当下，我们并不清楚，两个Service之间以及ThriftCLIService与客户端之间是如何完成交互的。本文将先从<code>SparkSQLCLIService</code>
	开始，看看在这个方向上能不能找到点线索。
</p>

<h2 class="jump">SparkSQLCLIService</h2>
<p>咱直接开始看代码吧！</p>
<pre class="brush: scala">
private[hive] class SparkSQLCLIService(hiveContext: HiveContext)
  extends CLIService with ReflectedCompositeService {

  override def init(hiveConf: HiveConf) {
    // this.hiveConf = hiveConf
    setSuperField(this, "hiveConf", hiveConf)

    // sessionManager = new SessionManager()
    val sparkSqlSessionManager = new SparkSQLSessionManager(hiveContext)
    setSuperField(this, "sessionManager", sparkSqlSessionManager)
    // addService(sessionManager)
    addService(sparkSqlSessionManager)

    var sparkServiceUGI: UserGroupInformation = null

    if (ShimLoader.getHadoopShims.isSecurityEnabled) {
      try {
        HiveAuthFactory.loginFromKeytab(hiveConf)
        sparkServiceUGI = ShimLoader.getHadoopShims.getUGIForConf(hiveConf)
        HiveThriftServerShim.setServerUserName(sparkServiceUGI, this)
      } catch {
        case e @ (_: IOException | _: LoginException) =>
          throw new ServiceException("Unable to login to kerberos with given principal/keytab", e)
      }
    }

    // super.init(hiveConf)
    initCompositeService(hiveConf)
  }

  // ...
}
</pre>
<p>
	首先我们看到SparkSQLCLISerivce继承自<code>CLIService</code>，同时混入了<code>ReflectedCompositeService</code>特质
	（如果你已经忘了ReflectedCompositeService，可以<a href="/applications/2015/07/27/SparkSQL-HiveThriftServer-Source-1.html#ReflectedCompositeService">点此回顾前文</a>）。
	由此可见，<code>CompositeService</code>应该也是SparkSQLCLIService的父类之一。对比于CLIService的init方法（其部分源代码已以行注释的形式在上述对应代码中给出），
	SparkSQLCLIService的init方法可以说完全是在做一模一样的事情，不同点仅在于CLIService启动一个<code>SessionManager</code>，而SparkSQLCLIService启动了一个<code>SparkSQLSessionManager</code>。
	我觉得光从名字上都能判断出来，SparkSQLSessionManager一定继承自SessionManager。
</p>
<p>让我们继续一探究竟吧！</p>

<h2 class="jump">SparkSQLSessionManager</h2>

<pre class="brush: scala">
private[hive] class SparkSQLSessionManager(hiveContext: HiveContext)
  extends SessionManager
  with ReflectedCompositeService {

  private lazy val sparkSqlOperationManager = new SparkSQLOperationManager(hiveContext)

  override def init(hiveConf: HiveConf) {
    // this.hiveConf = hiveConf
    setSuperField(this, "hiveConf", hiveConf)

    // int backgroundPoolSize = hiveConf.getIntVar(ConfVars.HIVE_SERVER2_ASYNC_EXEC_THREADS)
    val backgroundPoolSize = hiveConf.getIntVar(ConfVars.HIVE_SERVER2_ASYNC_EXEC_THREADS)
    // backgroundOperationPool = new ThreadPoolExecutor(backgroundPoolSize, backgroundPoolSize,
    //     keepAliveTime, TimeUnit.SECONDS, new LinkedBlockingQueue&lt;Runnable>(backgroundPoolQueueSize))
    setSuperField(this, "backgroundOperationPool", Executors.newFixedThreadPool(backgroundPoolSize))
    getAncestorField[Log](this, 3, "LOG").info(
      s"HiveServer2: Async execution pool size $backgroundPoolSize")

    // addService(operationManager)
    setSuperField(this, "operationManager", sparkSqlOperationManager)
    addService(sparkSqlOperationManager)

    // super.init(hiveConf)
    initCompositeService(hiveConf)
  }

  override def openSession(
      protocol: TProtocolVersion,
      username: String,
      passwd: String,
      sessionConf: java.util.Map[String, String],
      withImpersonation: Boolean,
      delegationToken: String): SessionHandle = {
	// 在HiveContext中创建SQLSession
    hiveContext.openSession()
	// 利用SessionManager创建HiveSession
    val sessionHandle = super.openSession(
      protocol, username, passwd, sessionConf, withImpersonation, delegationToken)
    val session = super.getSession(sessionHandle)
	// 通知HiveThriftServer2Listener有新的HiveSession被创建
    HiveThriftServer2.listener.onSessionCreated(
      session.getIpAddress, sessionHandle.getSessionId.toString, session.getUsername)
    sessionHandle
  }

  override def closeSession(sessionHandle: SessionHandle) {
	// 通知HiveThriftServer2Listener有HiveSession被关闭
    HiveThriftServer2.listener.onSessionClosed(sessionHandle.getSessionId.toString)
	// 利用SessionManager关闭HiveSession
    super.closeSession(sessionHandle)
    sparkSqlOperationManager.sessionToActivePool -= sessionHandle

	// 在HiveContext中关闭SQLSession
    hiveContext.detachSession()
  }
}
</pre>
<p>
	果不其然，SparkSQLSessionManager的init方法与SessionManager的init方法极为相似。
	从名字上看，Session Manager当然是用来管理Session的了。SparkSQLSessionManager的openSession和closeSession方法都有调用SessionManager的对应方法来管理HiveSession，
	同时还管理了HiveContext内部的SQLSession。简单的查看HiveSession和SQLSession的定义，可以得出结论，HiveSession
	指的是Hive ThriftServer与Client之间的Session，即通常意义上的网络Session；
	而SQLSession指的是SparkSQL与Hive ThriftServer之间的Session，但SQLSession实际存储的只是一系列与SQL查询有关的配置参数，和传统意义上的网络Session不同。
</p>
<p>
	SparkSQLSessionManager与SessionManager的不同点在于SparkSQLSessionManager启动了一个<code>SparkSQLOperationManager</code>，
	而SessionManager启动的是<code>OperationManager</code>。那么，其实也能猜到一些了。
</p>

<h2 class="jump">SparkSQLOperationManager</h2>
<pre class="brush: scala">
/**
 * Executes queries using Spark SQL, and maintains a list of handles to active queries.
 */
private[thriftserver] class SparkSQLOperationManager(hiveContext: HiveContext)
  extends OperationManager with Logging {

  val handleToOperation = ReflectionUtils.getSuperField[JMap[OperationHandle, Operation]](this, "handleToOperation")

  val sessionToActivePool = Map[SessionHandle, String]()

  override def newExecuteStatementOperation(
      parentSession: HiveSession,
      statement: String,
      confOverlay: JMap[String, String],
      async: Boolean): ExecuteStatementOperation = synchronized {

    // 利用session、statement、conf相关信息创建一个SparkExecuteStatementOperation
    val operation = new SparkExecuteStatementOperation(parentSession, statement, confOverlay)(
      hiveContext, sessionToActivePool)
    handleToOperation.put(operation.getHandle, operation)
    operation
  }
}
</pre>
<p>
	简短，直白。很明显，<code>newExecuteStatementOperation</code>方法会在客户端发送JDBC请求后被调用。方法
	创建了一个SparkExecuteStatementOperation，并将其进行缓存管理。实际上，SparkSQLOperationManager只复写了
	OperationManager的newExecuteStatementOperation方法，除此之外OperationManager还有<code>newGetSchemasOperation</code>
	等其他方法。这些方法从命名上判断，都是用户在查询表的元数据时才会触发的操作，比如newGetSchemasOperation应该是会在用户
	试图查询某张表的模式的时候才会触发的操作。SparkSQL之所以要重载newExecuteStatementOperation的原因是显然的：Execute意味着
	执行，SparkSQL Hive ThriftServer通过重载该方法，把用户通过execQuery发送的执行请求转发至SparkSQL。
</p>

<p>那就直接看看SparkExecuteStatementOperation到底干了什么吧（如果你已经猜到了，我并不会觉得意外 ;-) ）。</p>

<h2 class="jump">SparkExecuteStatementOperation</h2>
<pre class="brush: scala">
private[hive] class SparkExecuteStatementOperation(
    parentSession: HiveSession,
    statement: String,
    confOverlay: JMap[String, String],
    runInBackground: Boolean = true)(
    hiveContext: HiveContext,
    sessionToActivePool: SMap[SessionHandle, String])
  // NOTE: `runInBackground` is set to `false` intentionally to disable asynchronous execution
  extends ExecuteStatementOperation(parentSession, statement, confOverlay, false) with Logging {

  /** 执行结果 */
  private var result: DataFrame = _
  private var iter: Iterator[SparkRow] = _
  private var dataTypes: Array[DataType] = _

  def close(): Unit = {
    // RDDs will be cleaned automatically upon garbage collection.
    logDebug("CLOSING")
  }

  // ...

  /** 获取ResultSet的下一行（注意该类有一个iter成员变量） */
  def getNextRowSet(order: FetchOrientation, maxRowsL: Long): RowSet = {
    // ...
  }

  /** 获取ResultSet的模式（所包含域的名和类型） */
  def getResultSetSchema: TableSchema = {
    // ...
  }

  /** 执行查询，结果放入result变量并生成对应iter */
  def run(): Unit = {
    val statementId = UUID.randomUUID().toString
    logInfo(s"Running query '$statement'")
    setState(OperationState.RUNNING)
	// 通知Server，即将开始进行运算
    HiveThriftServer2.listener.onStatementStart(
      statementId,
      parentSession.getSessionHandle.getSessionId.toString,
      statement,
      statementId,
      parentSession.getUsername)
    hiveContext.sparkContext.setJobGroup(statementId, statement)
    sessionToActivePool.get(parentSession.getSessionHandle).foreach { pool =>
      hiveContext.sparkContext.setLocalProperty("spark.scheduler.pool", pool)
    }
    try {
	  // 噢吼
      result = hiveContext.sql(statement)
      
	  logDebug(result.queryExecution.toString())
      result.queryExecution.logical match {
        case SetCommand(Some((SQLConf.THRIFTSERVER_POOL, Some(value))), _) =>
          sessionToActivePool(parentSession.getSessionHandle) = value
          logInfo(s"Setting spark.scheduler.pool=$value for future statements in this session.")
        case _ =>
      }
	  // 通知Server，运算已完成
      HiveThriftServer2.listener.onStatementParsed(statementId, result.queryExecution.toString())
	  // 提取结果DataFrame的Iterator
      iter = {
        val useIncrementalCollect =
          hiveContext.getConf("spark.sql.thriftServer.incrementalCollect", "false").toBoolean
        if (useIncrementalCollect) {
          result.rdd.toLocalIterator
        } else {
          result.collect().iterator
        }
      }
      dataTypes = result.queryExecution.analyzed.output.map(_.dataType).toArray
      setHasResultSet(true)
    } catch {
      // Actually do need to catch Throwable as some failures don't inherit from Exception and
      // HiveServer will silently swallow them.
      case e: Throwable =>
        setState(OperationState.ERROR)
        HiveThriftServer2.listener.onStatementError(
          statementId, e.getMessage, e.getStackTraceString)
        logError("Error executing query:", e)
        throw new HiveSQLException(e.toString)
    }
    setState(OperationState.FINISHED)
    HiveThriftServer2.listener.onStatementFinish(statementId)
  }
}
</pre>

<p>
	那其实就很一目了然了：用户通过JDBC execQuery发送的请求最终被原封不动地转发到了HiveContext.sql上进行运算，
	结果保存在SparkExecuteStatementOperation中，同时保存一个Iterator，视客户端所需逐行逐行地以ResultSet的形式取出，
	并返回至客户端。
</p>
<p>至此，SparkSQLCLIService一侧的运作原理就基本探索完毕了。</p>

<h2 class="jump">总结</h2>
<p>在深入了解过SparkSQLCLIService一侧的原理以后，之前那张图大概就会变成下面这个样子：</p>
<p class="center"><img style="width: 100%" alt="" src="/img/SparkSQL@3.jpg"></p>
<p>
	总体而言，Spark Hive ThriftServer确实是基于Apache Hive的基础之上通过少量的修改、继承甚至是利用Java反射机制来hack Hive原本的
	类来将Hive本该转发至Hadoop MapReduce的操作转发到了SparkSQL的HiveContext.sql，因此在JDBC上调用execQuery和直接调用HiveContext.sql
	的效果是一致的。
</p>
<p>
	除了SparkSQLCLISerivce，ThriftCLIService侧的代码其实都是Apache Hive本身的代码，Spark未对其进行任何改写。Spark Hive ThriftServer项目
	本身的所有代码仅包括SparkSQLCLIService这一侧的代码和Spark SQL Shell的代码。因此总体而言，在阅读完本篇文章后，
	你应该已经完全了解Spark Hive ThriftServer的工作原理了。Hive ThriftCLIService一侧的代码很有可能我不会再去看了，因为
	那一侧的代码的功能已经十分明确，但由于涉及到网络通信，毫无疑问那一侧的代码量将会是这一侧的好几倍。因此如果你
	只是想了解SparkSQL Hive Server的运作原理，你的目的已经达到了。恭喜你！
</p>

			<!-- and ends here -->
			<script type="text/javascript">SyntaxHighlighter.all()</script>
			<div class="blank" style="height: 80px"></div>
			<!-- Disqus Block starts here -->
			<div id="disqus_thread"></div>
			<script type="text/javascript">
				/* * * CONFIGURATION VARIABLES * * */
				var disqus_shortname = 'robertpsblog';
				var disqus_identifier = 'SparkSQL Hive ThriftServer 源码解析（二）：SparkSQLCLIService';
    
				/* * * DON'T EDIT BELOW THIS LINE * * */
				(function() {
					var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
					dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
					(document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
				})();
			</script>
			<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>
			<!-- and ends here -->
		</div>
    </div>
    </div>
</body>
</html>